# -*- coding: utf-8 -*-
"""An√°lise Estat√≠stica de Pre√ßos de Combust√≠veis

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1b8MkbCCS-6rPUTFb_a5UKeZVu1OqaAN5
"""

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# --- Bloco de Fun√ß√µes ---

def carregar_e_limpar_dados(caminho_arquivo):
    """
    Carrega o arquivo Excel, converte a coluna de pre√ßos para num√©rico
    e remove dados inv√°lidos ou nulos.
    """
    try:
        df = pd.read_excel(caminho_arquivo)
    except FileNotFoundError:
        print(f"Erro: Arquivo '{caminho_arquivo}' n√£o encontrado.")
        return None
    except Exception as e:
        print(f"Ocorreu um erro ao ler o arquivo Excel: {e}")
        return None

    # Renomear colunas para remover espa√ßos e caracteres especiais
    df.columns = df.columns.str.strip().str.replace(' - ', '_').str.replace(' ', '_')

    if 'Valor_de_Venda' not in df.columns:
        print("Erro: A coluna 'Valor de Venda' n√£o foi encontrada no arquivo.")
        return None

    df['Valor_de_Venda'] = pd.to_numeric(df['Valor_de_Venda'], errors='coerce')
    df.dropna(subset=['Valor_de_Venda'], inplace=True)
    df = df[df['Valor_de_Venda'] > 0]

    return df


def calcular_estatisticas_descritivas(df, coluna_grupo, coluna_valor):
    """
    Calcula e retorna um DataFrame com as principais estat√≠sticas descritivas
    agrupadas por uma coluna espec√≠fica.
    """
    produtos_comuns = ['GASOLINA', 'ETANOL', 'DIESEL S10', 'GASOLINA ADITIVADA']
    df_filtrado = df[df[coluna_grupo].isin(produtos_comuns)]

    stats_df = pd.DataFrame()
    grouped = df_filtrado.groupby(coluna_grupo)[coluna_valor]

    stats_df['media'] = grouped.mean()
    stats_df['mediana'] = grouped.median()
    stats_df['moda'] = grouped.apply(lambda x: x.mode().iloc[0] if not x.mode().empty else None)
    stats_df['desvio_padrao'] = grouped.std()
    stats_df['variancia'] = grouped.var()
    stats_df['min'] = grouped.min()
    stats_df['25%'] = grouped.quantile(0.25)
    stats_df['75%'] = grouped.quantile(0.75)
    stats_df['max'] = grouped.quantile(1.0)
    stats_df['assimetria'] = grouped.skew()
    stats_df['curtose'] = grouped.apply(lambda x: x.kurt())  # corrigido

    return stats_df.round(4)


def calcular_matriz_covariancia(df, col_indices, col_pivot, col_valores):
    """
    Calcula e retorna a matriz de covari√¢ncia para os valores de uma coluna
    pivotada.
    """
    produtos_comuns = ['GASOLINA', 'ETANOL', 'DIESEL S10', 'GASOLINA ADITIVADA']
    df_filtrado = df[df[col_pivot].isin(produtos_comuns)]

    df_pivot = df_filtrado.pivot_table(index=col_indices,
                                       columns=col_pivot,
                                       values=col_valores)
    df_pivot.dropna(inplace=True)

    if len(df_pivot) > 1:
        return df_pivot.cov().round(4)
    else:
        return "Dados insuficientes para calcular a covari√¢ncia."


def gerar_graficos(df, coluna_grupo, coluna_valor):
    """
    Gera e salva os gr√°ficos de an√°lise (Histograma, Box Plot, Percentil, Assimetria e Curtose).
    """
    produtos_comuns = ['GASOLINA', 'ETANOL', 'DIESEL S10', 'GASOLINA ADITIVADA']
    df_filtrado = df[df[coluna_grupo].isin(produtos_comuns)]

    sns.set_theme(style="whitegrid", palette="viridis")

    # 1. Histograma e Densidade para Gasolina
    plt.figure(figsize=(10, 6))
    sns.histplot(data=df_filtrado[df_filtrado[coluna_grupo] == 'GASOLINA'],
                 x=coluna_valor, kde=True, bins=30)
    plt.title('Distribui√ß√£o de Pre√ßos da Gasolina Comum', fontsize=16)
    plt.xlabel('Valor de Venda (R$ / litro)', fontsize=12)
    plt.ylabel('Frequ√™ncia', fontsize=12)
    plt.savefig('histograma_gasolina.png')
    plt.show()

    # 2. Box Plot Comparativo
    plt.figure(figsize=(12, 8))
    sns.boxplot(x=coluna_grupo, y=coluna_valor, data=df_filtrado, order=produtos_comuns)
    plt.title('Dispers√£o dos Pre√ßos por Tipo de Combust√≠vel', fontsize=16)
    plt.xlabel('Produto', fontsize=12)
    plt.ylabel('Valor de Venda (R$ / litro)', fontsize=12)
    plt.savefig('boxplot_comparativo.png')
    plt.show()

    # 3. Gr√°fico de Percentil
    plt.figure(figsize=(12, 8))
    for produto in produtos_comuns:
        sns.ecdfplot(data=df_filtrado[df_filtrado[coluna_grupo] == produto],
                     x=coluna_valor, label=produto)
    plt.title('Gr√°fico de Percentil dos Pre√ßos por Tipo de Combust√≠vel', fontsize=16)
    plt.xlabel('Valor de Venda (R$ / litro)', fontsize=12)
    plt.ylabel('Percentil', fontsize=12)
    plt.legend()
    plt.savefig('percentil_precos.png')
    plt.show()

    # 4. Gr√°fico de Assimetria
    skewness_data = df_filtrado.groupby(coluna_grupo)[coluna_valor].skew().reindex(produtos_comuns)
    plt.figure(figsize=(10, 6))
    sns.barplot(x=skewness_data.index, y=skewness_data.values)
    plt.title('Assimetria dos Pre√ßos por Tipo de Combust√≠vel', fontsize=16)
    plt.xlabel('Produto', fontsize=12)
    plt.ylabel('Assimetria', fontsize=12)
    plt.savefig('assimetria_precos.png')
    plt.show()

    # 5. Gr√°fico de Curtose
    kurtosis_data = df_filtrado.groupby(coluna_grupo)[coluna_valor].apply(lambda x: x.kurt()).reindex(produtos_comuns)
    plt.figure(figsize=(10, 6))
    sns.barplot(x=kurtosis_data.index, y=kurtosis_data.values)
    plt.title('Curtose dos Pre√ßos por Tipo de Combust√≠vel', fontsize=16)
    plt.xlabel('Produto', fontsize=12)
    plt.ylabel('Curtose', fontsize=12)
    plt.savefig('curtose_precos.png')
    plt.show()


# --- Execu√ß√£o Principal ---

if __name__ == "__main__":
    arquivo_csv = "Pre√ßos_Automotivos_Parana.xlsx"

    dados = carregar_e_limpar_dados(arquivo_csv)

    if dados is not None:
        estatisticas = calcular_estatisticas_descritivas(dados, 'Produto', 'Valor_de_Venda')
        print("--- An√°lise Descritiva por Produto ---")
        display(estatisticas)
        print("\n" + "="*50 + "\n")

        matriz_cov = calcular_matriz_covariancia(dados,
                                                 ['CNPJ_da_Revenda', 'Data_da_Coleta'],
                                                 'Produto',
                                                 'Valor_de_Venda')
        print("--- Matriz de Covari√¢ncia entre Pre√ßos ---")
        display(matriz_cov)
        print("\n" + "="*50 + "\n")

        print("Gerando gr√°ficos de an√°lise...")
        gerar_graficos(dados, 'Produto', 'Valor_de_Venda')
        print("Gr√°ficos 'histograma_gasolina.png', 'boxplot_comparativo.png', "
              "'percentil_precos.png', 'assimetria_precos.png', e 'curtose_precos.png' salvos no diret√≥rio.")

# ============================================================
# üìò AN√ÅLISE DE REGRESS√ÉO LINEAR E N√ÉO LINEAR EM PYTHON
# ============================================================
# Autor: Guilherme Candida de Amorim
# Descri√ß√£o:
# Este notebook realiza uma an√°lise comparativa entre modelos
# de regress√£o linear e n√£o linear aplicados ao pre√ßo m√©dio
# da gasolina no Paran√°. S√£o utilizados diferentes m√©todos de
# estima√ß√£o e otimiza√ß√£o: M√≠nimos Quadrados, Gauss-Newton,
# Levenberg‚ÄìMarquardt, M√°xima Verossimilhan√ßa e Bayesianos.
# ============================================================

# --- Etapa 0: Instalar e Importar Bibliotecas ---
!pip install pymc -q

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import pymc as pm
from sklearn.linear_model import LinearRegression
from sklearn.preprocessing import PolynomialFeatures
from sklearn.metrics import mean_squared_error, r2_score
from scipy.optimize import curve_fit, minimize
import warnings
warnings.filterwarnings('ignore')

# --- Etapa 1: Carregar o Arquivo Excel ---
caminho_do_arquivo = '/content/Pre√ßos_Automotivos_Parana.xlsx'  # <--- Substitua se necess√°rio

try:
    df = pd.read_excel(caminho_do_arquivo)
    print(f"‚úÖ Arquivo '{caminho_do_arquivo}' carregado com sucesso!")
except FileNotFoundError:
    print(f"‚ùå ERRO: O arquivo '{caminho_do_arquivo}' n√£o foi encontrado.")
    df = None
except Exception as e:
    print(f"‚ö†Ô∏è Erro ao ler o arquivo: {e}")
    df = None

# --- Etapa 2: Pr√©-processamento e Sele√ß√£o dos Dados ---
if df is not None:
    df.columns = df.columns.str.strip()
    if 'Data da Coleta' in df.columns and 'Valor de Venda' in df.columns:
        df['Data da Coleta'] = pd.to_datetime(df['Data da Coleta'])
        df['Valor de Venda'] = pd.to_numeric(df['Valor de Venda'], errors='coerce')
        df.dropna(subset=['Data da Coleta', 'Valor de Venda'], inplace=True)

        # Filtrar apenas gasolina
        if 'Produto' in df.columns:
            df_gasolina = df[df['Produto'] == 'GASOLINA'].copy()
        else:
            print("‚ö†Ô∏è Coluna 'Produto' n√£o encontrada. Usando todos os dados.")
            df_gasolina = df.copy()

        if df_gasolina.empty:
            print("‚ùå Nenhum dado de GASOLINA encontrado.")
        else:
            df_daily = df_gasolina.groupby('Data da Coleta')['Valor de Venda'].mean().reset_index()
            df_daily['Dias'] = (df_daily['Data da Coleta'] - df_daily['Data da Coleta'].min()).dt.days

            X = df_daily[['Dias']]
            y = df_daily['Valor de Venda']
            x_data = X['Dias'].values
            y_data = y.values

            # Visualizar dados iniciais
            plt.figure(figsize=(10,5))
            plt.scatter(df_daily['Data da Coleta'], df_daily['Valor de Venda'], color='blue', alpha=0.6)
            plt.title('üìà Pre√ßo M√©dio da Gasolina ao Longo do Tempo')
            plt.xlabel('Data da Coleta')
            plt.ylabel('Valor de Venda (R$)')
            plt.grid(True)
            plt.show()

            resultados = []  # tabela comparativa final

            # ============================================================
            # 1Ô∏è‚É£ Regress√£o Linear Simples
            # ============================================================
            print("\n--- 1. Regress√£o Linear Simples ---")
            linear_model = LinearRegression()
            linear_model.fit(X, y)
            y_pred_linear = linear_model.predict(X)
            r2_linear = r2_score(y, y_pred_linear)
            rmse_linear = np.sqrt(mean_squared_error(y, y_pred_linear))
            resultados.append(['Linear', 'M√≠nimos Quadrados', r2_linear, rmse_linear])

            print(f"R¬≤: {r2_linear:.4f} | RMSE: {rmse_linear:.4f}")
            print(f"Equa√ß√£o: y = {linear_model.coef_[0]:.6f}x + {linear_model.intercept_:.4f}")

            plt.figure(figsize=(10,5))
            plt.scatter(X, y, label='Dados')
            plt.plot(X, y_pred_linear, color='red', label='Regress√£o Linear')
            plt.title('Regress√£o Linear Simples')
            plt.xlabel('Dias')
            plt.ylabel('Pre√ßo (R$)')
            plt.legend(); plt.grid(True); plt.show()

            # ============================================================
            # 2Ô∏è‚É£ Regress√£o Polinomial (Par√°bola)
            # ============================================================
            print("\n--- 2. Regress√£o Polinomial (Grau 2 - Par√°bola) ---")
            poly_features = PolynomialFeatures(degree=2)
            X_poly = poly_features.fit_transform(X)
            poly_model = LinearRegression()
            poly_model.fit(X_poly, y)
            y_pred_poly = poly_model.predict(X_poly)
            r2_poly = r2_score(y, y_pred_poly)
            rmse_poly = np.sqrt(mean_squared_error(y, y_pred_poly))
            resultados.append(['Polinomial (Grau 2)', 'M√≠nimos Quadrados', r2_poly, rmse_poly])

            print(f"R¬≤: {r2_poly:.4f} | RMSE: {rmse_poly:.4f}")
            print(f"Equa√ß√£o: y = {poly_model.coef_[2]:.6f}x¬≤ + {poly_model.coef_[1]:.6f}x + {poly_model.intercept_:.4f}")

            plt.figure(figsize=(10,5))
            plt.scatter(X, y, label='Dados')
            plt.plot(X, y_pred_poly, color='green', label='Regress√£o Polinomial')
            plt.title('Regress√£o Polinomial (Grau 2)')
            plt.xlabel('Dias')
            plt.ylabel('Pre√ßo (R$)')
            plt.legend(); plt.grid(True); plt.show()

            # ============================================================
            # 3Ô∏è‚É£ Modelos N√£o Lineares (Exponencial)
            # ============================================================
            print("\n==================================================")
            print("3. Modelos N√£o Lineares (Exponencial)")
            print("==================================================")

            def func_exp(x, a, b, c):
                return a * np.exp(b * x) + c

            # --- Levenberg‚ÄìMarquardt ---
            print("\n--- 3a. M√≠nimos Quadrados (Levenberg‚ÄìMarquardt) ---")
            try:
                popt_lm, _ = curve_fit(func_exp, x_data, y_data, p0=(5, 0.001, 1), method='lm', maxfev=5000)
                y_pred_exp_lm = func_exp(x_data, *popt_lm)
                r2_exp_lm = r2_score(y_data, y_pred_exp_lm)
                rmse_exp_lm = np.sqrt(mean_squared_error(y_data, y_pred_exp_lm))
                resultados.append(['Exponencial', 'Levenberg‚ÄìMarquardt', r2_exp_lm, rmse_exp_lm])
                print(f"R¬≤: {r2_exp_lm:.4f} | RMSE: {rmse_exp_lm:.4f}")
            except Exception as e:
                print(f"Erro LM: {e}")

            # --- Gauss‚ÄìNewton (TRF) ---
            print("\n--- 3b. M√≠nimos Quadrados (Gauss‚ÄìNewton via TRF) ---")
            try:
                popt_trf, _ = curve_fit(func_exp, x_data, y_data, p0=(5, 0.001, 1), method='trf', maxfev=5000)
                y_pred_exp_trf = func_exp(x_data, *popt_trf)
                r2_exp_trf = r2_score(y_data, y_pred_exp_trf)
                rmse_exp_trf = np.sqrt(mean_squared_error(y_data, y_pred_exp_trf))
                resultados.append(['Exponencial', 'Gauss‚ÄìNewton (TRF)', r2_exp_trf, rmse_exp_trf])
                print(f"R¬≤: {r2_exp_trf:.4f} | RMSE: {rmse_exp_trf:.4f}")
            except Exception as e:
                print(f"Erro TRF: {e}")

            # --- M√°xima Verossimilhan√ßa (MLE) ---
            print("\n--- 3c. M√°xima Verossimilhan√ßa (MLE) ---")
            def nll(params, x, y):
                a, b, c, sigma = params
                y_pred = func_exp(x, a, b, c)
                likelihood = -np.sum(np.log(np.sqrt(2*np.pi*sigma**2))) - (1/(2*sigma**2))*np.sum((y - y_pred)**2)
                return -likelihood

            initial_params = [5.0, 0.001, 1.0, np.std(y_data)]
            mle_results = minimize(nll, initial_params, args=(x_data, y_data), method='L-BFGS-B')
            if mle_results.success:
                popt_mle = mle_results.x[:3]
                y_pred_exp_mle = func_exp(x_data, *popt_mle)
                r2_exp_mle = r2_score(y_data, y_pred_exp_mle)
                rmse_exp_mle = np.sqrt(mean_squared_error(y_data, y_pred_exp_mle))
                resultados.append(['Exponencial', 'M√°xima Verossimilhan√ßa', r2_exp_mle, rmse_exp_mle])
                print(f"R¬≤: {r2_exp_mle:.4f} | RMSE: {rmse_exp_mle:.4f}")
            else:
                print("Falha MLE.")

            # --- M√©todos Bayesianos ---
            print("\n--- 3d. M√©todo Bayesiano (MCMC via PyMC) ---")
            try:
                with pm.Model() as bayesian_model:
                    a = pm.Normal('a', mu=np.mean(y_data), sigma=np.std(y_data))
                    b = pm.Normal('b', mu=0, sigma=1)
                    c = pm.Normal('c', mu=np.mean(y_data), sigma=np.std(y_data))
                    sigma = pm.HalfNormal('sigma', sigma=np.std(y_data))
                    mu = a * pm.math.exp(b * x_data) + c
                    Y_obs = pm.Normal('Y_obs', mu=mu, sigma=sigma, observed=y_data)
                    trace = pm.sample(1000, tune=1000, cores=1, progressbar=False)

                popt_bayes = [
                    trace.posterior['a'].mean().item(),
                    trace.posterior['b'].mean().item(),
                    trace.posterior['c'].mean().item()
                ]
                y_pred_exp_bayes = func_exp(x_data, *popt_bayes)
                r2_exp_bayes = r2_score(y_data, y_pred_exp_bayes)
                rmse_exp_bayes = np.sqrt(mean_squared_error(y_data, y_pred_exp_bayes))
                resultados.append(['Exponencial', 'Bayesiano (MCMC)', r2_exp_bayes, rmse_exp_bayes])
                print(f"R¬≤: {r2_exp_bayes:.4f} | RMSE: {rmse_exp_bayes:.4f}")
            except Exception as e:
                print(f"Erro Bayesiano: {e}")

            # ============================================================
            # 4Ô∏è‚É£ Compara√ß√£o Gr√°fica dos Modelos Exponenciais
            # ============================================================
            plt.figure(figsize=(12,7))
            plt.scatter(x_data, y_data, label='Dados Originais', color='black', zorder=10)
            if 'y_pred_exp_lm' in locals(): plt.plot(x_data, y_pred_exp_lm, label=f'LM (R¬≤={r2_exp_lm:.3f})')
            if 'y_pred_exp_trf' in locals(): plt.plot(x_data, y_pred_exp_trf, label=f'TRF (R¬≤={r2_exp_trf:.3f})', linestyle='--')
            if 'y_pred_exp_mle' in locals(): plt.plot(x_data, y_pred_exp_mle, label=f'MLE (R¬≤={r2_exp_mle:.3f})', linestyle=':')
            if 'y_pred_exp_bayes' in locals(): plt.plot(x_data, y_pred_exp_bayes, label=f'Bayes (R¬≤={r2_exp_bayes:.3f})', linestyle='-.')
            plt.title('Compara√ß√£o dos M√©todos para Regress√£o Exponencial')
            plt.xlabel('Dias'); plt.ylabel('Pre√ßo (R$)')
            plt.legend(); plt.grid(True); plt.show()

            # ============================================================
            # 5Ô∏è‚É£ Tabela Comparativa Final
            # ============================================================
            print("\n==================================================")
            print("üèÅ COMPARA√á√ÉO FINAL DOS MODELOS")
            print("==================================================")
            df_resultados = pd.DataFrame(resultados, columns=['Modelo', 'M√©todo de Otimiza√ß√£o', 'R¬≤', 'RMSE'])
            df_resultados = df_resultados.sort_values(by='R¬≤', ascending=False).reset_index(drop=True)

            print("R¬≤: mais pr√≥ximo de 1 √© melhor | RMSE: mais pr√≥ximo de 0 √© melhor\n")
            display(df_resultados.style.background_gradient(subset=['R¬≤'], cmap='Greens')
                               .background_gradient(subset=['RMSE'], cmap='Reds_r')
                               .format({'R¬≤': '{:.4f}', 'RMSE': '{:.4f}'}))

            melhor = df_resultados.iloc[0]
            print(f"\n‚úÖ Melhor modelo: {melhor['Modelo']} ({melhor['M√©todo de Otimiza√ß√£o']})")
            print(f"   R¬≤ = {melhor['R¬≤']:.4f} | RMSE = {melhor['RMSE']:.4f}")

    else:
        print("‚ùå Colunas 'Data da Coleta' e 'Valor de Venda' n√£o encontradas.")

# ===============================================================
# üìä DASHBOARD INTERATIVO DE REGRESS√ÉO LINEAR E N√ÉO LINEAR
# Projeto: Pre√ßo Justo PR
# Autores: Francisco Bueno Ghizelini & Guilherme Candida de Amorim
# ===============================================================
# Objetivo:
#   - Carregar dados de pre√ßos de combust√≠veis (gasolina)
#   - Aplicar regress√µes linear, polinomial, exponencial e pot√™ncia
#   - Visualizar e comparar resultados em um dashboard interativo
# ===============================================================

# --- Etapa 0: Importar Bibliotecas ---
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.linear_model import LinearRegression
from sklearn.preprocessing import PolynomialFeatures
from sklearn.metrics import r2_score
from scipy.optimize import curve_fit
import ipywidgets as widgets
from ipywidgets import interact
import os

# --- Etapa 1: Carregar o Arquivo Existente no Colab ---
# Coloque aqui o caminho do arquivo existente no seu ambiente
caminho_arquivo = "/content/Pre√ßos_Automotivos_Parana.xlsx"

if os.path.exists(caminho_arquivo):
    print(f"‚úÖ Arquivo encontrado: {caminho_arquivo}")
    df = pd.read_excel(caminho_arquivo)
else:
    print(f"‚ùå Arquivo n√£o encontrado em: {caminho_arquivo}")
    df = None

# --- Etapa 2: Processamento e Treinamento dos Modelos ---
if df is not None:
    df.columns = df.columns.str.strip()
    df['Data da Coleta'] = pd.to_datetime(df['Data da Coleta'], errors='coerce')
    df['Valor de Venda'] = pd.to_numeric(df['Valor de Venda'], errors='coerce')
    df.dropna(subset=['Data da Coleta', 'Valor de Venda'], inplace=True)

    if 'Produto' in df.columns:
        df_gasolina = df[df['Produto'].str.upper() == 'GASOLINA'].copy()
    else:
        df_gasolina = df.copy()

    if not df_gasolina.empty:
        df_daily = df_gasolina.groupby('Data da Coleta')['Valor de Venda'].mean().reset_index()
        df_daily['Dias'] = (df_daily['Data da Coleta'] - df_daily['Data da Coleta'].min()).dt.days

        X = df_daily[['Dias']]
        y = df_daily['Valor de Venda']
        X_flat = df_daily['Dias'].values

        predictions, metrics = {}, {}

        # ===============================================================
        # üîπ 1. Regress√£o Linear
        # ===============================================================
        linear_model = LinearRegression()
        linear_model.fit(X, y)
        predictions['Linear'] = linear_model.predict(X)
        metrics['Linear'] = {
            'R¬≤': r2_score(y, predictions['Linear']),
            'Equa√ß√£o': f"y = {linear_model.coef_[0]:.4f}x + {linear_model.intercept_:.4f}"
        }

        # ===============================================================
        # üîπ 2. Regress√£o Polinomial (Grau 2)
        # ===============================================================
        poly = PolynomialFeatures(degree=2)
        X_poly = poly.fit_transform(X)
        poly_model = LinearRegression()
        poly_model.fit(X_poly, y)
        predictions['Polinomial'] = poly_model.predict(X_poly)
        metrics['Polinomial'] = {
            'R¬≤': r2_score(y, predictions['Polinomial']),
            'Equa√ß√£o': f"y = {poly_model.coef_[2]:.6f}x¬≤ + {poly_model.coef_[1]:.4f}x + {poly_model.intercept_:.4f}"
        }

        # ===============================================================
        # üîπ 3. Regress√£o Exponencial
        # ===============================================================
        def func_exp(x, a, b):
            return a * np.exp(b * x)

        try:
            popt_exp, _ = curve_fit(func_exp, X_flat, y, p0=(5, 0.001), maxfev=5000)
            predictions['Exponencial'] = func_exp(X_flat, *popt_exp)
            metrics['Exponencial'] = {
                'R¬≤': r2_score(y, predictions['Exponencial']),
                'Equa√ß√£o': f"y = {popt_exp[0]:.4f} * e^({popt_exp[1]:.6f}x)"
            }
        except RuntimeError:
            print("‚ö†Ô∏è Aviso: N√£o foi poss√≠vel ajustar o modelo Exponencial.")

        # ===============================================================
        # üîπ 4. Regress√£o de Pot√™ncia
        # ===============================================================
        def func_pot(x, a, b):
            return a * np.power(x + 1e-9, b)  # evita log(0)

        try:
            popt_pot, _ = curve_fit(func_pot, X_flat, y, p0=(1, 0.1), maxfev=5000)
            predictions['Pot√™ncia'] = func_pot(X_flat, *popt_pot)
            metrics['Pot√™ncia'] = {
                'R¬≤': r2_score(y, predictions['Pot√™ncia']),
                'Equa√ß√£o': f"y = {popt_pot[0]:.4f} * x^({popt_pot[1]:.4f})"
            }
        except RuntimeError:
            print("‚ö†Ô∏è Aviso: N√£o foi poss√≠vel ajustar o modelo de Pot√™ncia.")

        # Modelos dispon√≠veis
        model_options = list(predictions.keys())

        # ===============================================================
        # --- Etapa 3: Fun√ß√£o de Atualiza√ß√£o do Dashboard ---
        # ===============================================================
        def update_dashboard(modelo):
            plt.figure(figsize=(12, 7))
            plt.scatter(X, y, color='royalblue', label='Dados Reais')

            ordem = np.argsort(X_flat)
            plt.plot(X_flat[ordem], np.array(predictions[modelo])[ordem],
                     color='darkred', linewidth=3, label=f'Modelo {modelo}')

            r2 = metrics[modelo]['R¬≤']
            eq = metrics[modelo]['Equa√ß√£o']

            plt.title(f"An√°lise de Regress√£o ({modelo})", fontsize=16, fontweight='bold')
            plt.xlabel("Dias desde a primeira coleta", fontsize=12)
            plt.ylabel("Pre√ßo m√©dio de venda (R$)", fontsize=12)
            plt.legend()
            plt.grid(True, linestyle='--', alpha=0.6)
            plt.text(0.05, 0.95, f"R¬≤ = {r2:.4f}\n{eq}", transform=plt.gca().transAxes,
                     fontsize=12, va='top', bbox=dict(boxstyle='round,pad=0.5', fc='wheat', alpha=0.5))
            plt.show()

        # ===============================================================
        # --- Etapa 4: Criar o Dashboard Interativo ---
        # ===============================================================
        print("\n" + "="*60)
        print("üìà DASHBOARD INTERATIVO DE REGRESS√ÉO")
        print("Selecione um modelo para visualizar o gr√°fico e m√©tricas.")
        print("="*60)

        interact(update_dashboard,
                 modelo=widgets.Dropdown(options=model_options, description='Modelo:'))

    else:
        print("‚ö†Ô∏è Nenhum dado de GASOLINA encontrado no arquivo.")
else:
    print("‚ùå O arquivo de dados n√£o foi encontrado. Verifique o caminho informado.")

# -*- coding: utf-8 -*-
"""
BLOCO √öNICO DE AN√ÅLISE DE DADOS - PROJETO PRE√áO JUSTO PR
Este script executa:
1.  Carregamento e Limpeza dos Dados
2.  An√°lise N√£o Supervisionada (Clusteriza√ß√£o)
    - K-Means (com M√©todo Elbow e PCA)
    - Hierarchical Clustering (com Dendrograma)
    - Expectation Maximization (GMM com crit√©rio BIC)
3.  An√°lise Supervisionada (Regress√£o para prever Pre√ßo)
    - √Årvore de Decis√£o, Random Forest, KNN, Rede Neural
    - Avalia√ß√£o: R¬≤ e RMSE
4.  An√°lise Supervisionada (Classifica√ß√£o para prever Produto)
    - √Årvore de Decis√£o, Random Forest, KNN, Rede Neural
    - Avalia√ß√£o: Acur√°cia, F1-Score e Matriz de Confus√£o
5.  Comparativo final dos modelos
"""

# ================================================================
# C√âLULA 1: IMPORTS E FUN√á√ÉO DE CARREGAMENTO
# ================================================================

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np

# --- Bibliotecas de Clusteriza√ß√£o (N√£o Supervisionado) ---
from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder
from sklearn.pipeline import Pipeline
from sklearn.compose import ColumnTransformer
from sklearn.cluster import KMeans, AgglomerativeClustering
from sklearn.mixture import GaussianMixture
from sklearn.metrics import silhouette_score, davies_bouldin_score
from sklearn.decomposition import PCA
from scipy.cluster.hierarchy import dendrogram, linkage

# --- Bibliotecas de Modelos Supervisionados ---
from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor, plot_tree
from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor
from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor
from sklearn.neural_network import MLPClassifier, MLPRegressor

# --- M√©tricas de Avalia√ß√£o ---
from sklearn.metrics import (
    accuracy_score,
    confusion_matrix, classification_report,
    r2_score, mean_squared_error,
    precision_score, recall_score, f1_score # Corrected import
)

# --- Para exibir DataFrames de forma bonita no Colab ---
try:
    from IPython.display import display
except ImportError:
    display = print # Fallback para print()

# ================================================================
# FUN√á√ÉO DE CARREGAMENTO E LIMPEZA
# ================================================================

def carregar_e_limpar_dados(caminho_arquivo):
    """
    Carrega o arquivo Excel, converte a coluna de pre√ßos para num√©rico
    e remove dados inv√°lidos ou nulos.
    """
    try:
        df = pd.read_excel(caminho_arquivo)
    except FileNotFoundError:
        print(f"Erro: Arquivo '{caminho_arquivo}' n√£o encontrado.")
        print("Por favor, fa√ßa o upload do arquivo no menu 'Arquivos' √† esquerda.")
        return None
    except Exception as e:
        print(f"Ocorreu um erro ao ler o arquivo Excel: {e}")
        return None

    # Renomear colunas
    df.columns = df.columns.str.strip().str.replace(' - ', '_').str.replace(' ', '_')

    # Verifica colunas essenciais
    colunas_necessarias = ['Valor_de_Venda', 'Produto', 'CNPJ_da_Revenda', 'Municipio']

    # Checa se pelo menos as colunas de ML existem
    if 'Valor_de_Venda' not in df.columns or 'Produto' not in df.columns:
        print("Erro: A coluna 'Valor de Venda' ou 'Produto' n√£o foi encontrada.")
        return None

    # Checa colunas de agrupamento
    if 'CNPJ_da_Revenda' not in df.columns and 'Municipio' not in df.columns:
        print("AVISO: 'CNPJ_da_Revenda' ou 'Municipio' n√£o encontrados. A clusteriza√ß√£o pode falhar.")
        # Adiciona coluna 'Municipio' gen√©rica se n√£o existir, para n√£o quebrar o c√≥digo
        if 'Municipio' not in df.columns:
             df['Municipio'] = 'Parana'

    df['Valor_de_Venda'] = pd.to_numeric(df['Valor_de_Venda'], errors='coerce')
    df.dropna(subset=['Valor_de_Venda', 'Produto'], inplace=True)
    df = df[df['Valor_de_Venda'] > 0]

    # Filtra apenas os produtos de interesse para a an√°lise
    produtos_comuns = ['GASOLINA', 'ETANOL', 'DIESEL S10', 'GASOLINA ADITIVADA']
    df_filtrado = df[df['Produto'].isin(produtos_comuns)]

    print(f"Dados carregados e limpos. Total de {len(df_filtrado)} registros v√°lidos.")
    return df_filtrado

# --- Execu√ß√£o do Carregamento ---
arquivo_excel = "Pre√ßos_Automotivos_Parana.xlsx"
dados = carregar_e_limpar_dados(arquivo_excel)


# ================================================================
# C√âLULA 2: APRENDIZADO N√ÉO SUPERVISIONADO (CLUSTERIZA√á√ÉO)
# ================================================================

if dados is not None:
    print("\n" + "="*50)
    print("--- Iniciando An√°lise N√£o Supervisionada (Clusteriza√ß√£o) ---")

    # 1. Prepara√ß√£o dos Dados para Clusteriza√ß√£o
    index_col = 'CNPJ_da_Revenda'
    if index_col not in dados.columns:
        index_col = 'Municipio' # Usa Munic√≠pio se CNPJ n√£o existir

    print(f"Agrupando dados por: {index_col}")
    df_pivot = dados.pivot_table(index=index_col,
                                 columns='Produto',
                                 values='Valor_de_Venda',
                                 aggfunc='mean')

    df_pivot.dropna(inplace=True) # Remove quem n√£o vende os 4 produtos

    dados_cluster = None
    if len(df_pivot) < 10:
         print(f"AVISO: Poucos dados ({len(df_pivot)} registros) para clusteriza√ß√£o ap√≥s pivotar.")
    else:
        print(f"Dados pivotados prontos: {df_pivot.shape}")
        scaler = StandardScaler()
        dados_cluster = scaler.fit_transform(df_pivot)


    if dados_cluster is not None:

        # --- 2. K-Means Clustering ---
        print("\n[Executando K-Means...]")

        # (A) Avalia√ß√£o: M√©todo Elbow
        inercias = []
        ks = range(2, 10)
        for k in ks:
            kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)
            kmeans.fit(dados_cluster)
            inercias.append(kmeans.inertia_)

        # (B) Gr√°fico: Elbow
        plt.figure(figsize=(10, 6))
        plt.plot(ks, inercias, 'bx-')
        plt.xlabel('N√∫mero de Clusters (k)')
        plt.ylabel('In√©rcia')
        plt.title('M√©todo Elbow para K-Means')
        plt.savefig('cluster_kmeans_elbow.png')
        plt.show()

        K_ESCOLHIDO = 4 # Escolha baseada no "cotovelo"
        kmeans = KMeans(n_clusters=K_ESCOLHIDO, random_state=42, n_init=10)
        clusters_kmeans = kmeans.fit_predict(dados_cluster)

        # (A) Avalia√ß√£o 2: Silhoutte Score
        score_sil = silhouette_score(dados_cluster, clusters_kmeans)
        print(f"K-Means (k={K_ESCOLHIDO}) - Silhouette Score: {score_sil:.4f}")

        # (B) Gr√°fico: Visualiza√ß√£o dos Clusters com PCA
        pca = PCA(n_components=2)
        dados_pca = pca.fit_transform(dados_cluster)
        plt.figure(figsize=(10, 7))
        sns.scatterplot(x=dados_pca[:, 0], y=dados_pca[:, 1], hue=clusters_kmeans, palette='viridis', s=100, alpha=0.7)
        plt.title('Clusters K-Means (Visualiza√ß√£o com PCA)')
        plt.xlabel('Componente Principal 1')
        plt.ylabel('Componente Principal 2')
        plt.legend(title='Cluster')
        plt.savefig('cluster_kmeans_pca.png')
        plt.show()

        # --- 3. Hierarchical Clustering ---
        print("\n[Executando Hierarchical Clustering...]")

        # (B) Gr√°fico: Dendrograma
        linkage_matrix = linkage(dados_cluster, method='ward')
        plt.figure(figsize=(15, 8))
        dendrogram(linkage_matrix, labels=df_pivot.index, leaf_rotation=90, leaf_font_size=8, truncate_mode='level', p=5)
        plt.title('Dendrograma do Cluster Hier√°rquico (N√≠veis=5)')
        plt.xlabel('Registros (Postos/Munic√≠pios)')
        plt.ylabel('Dist√¢ncia')
        plt.savefig('cluster_hierarchical_dendrogram.png')
        plt.show()

        # --- 4. Expectation Maximization (Gaussian Mixture Models) ---
        print("\n[Executando Expectation Maximization (GMM)...]")

        # (A) Avalia√ß√£o: Crit√©rio de Informa√ß√£o Bayesiano (BIC)
        n_componentes = range(2, 10)
        bics = []
        for n in n_componentes:
            gmm = GaussianMixture(n_components=n, random_state=42)
            gmm.fit(dados_cluster)
            bics.append(gmm.bic(dados_cluster))

        # (B) Gr√°fico: BIC
        plt.figure(figsize=(10, 6))
        plt.plot(n_componentes, bics, 'bx-')
        plt.xlabel('N√∫mero de Componentes')
        plt.ylabel('BIC Score (Quanto menor, melhor)')
        plt.title('Crit√©rio BIC para GMM')
        plt.savefig('cluster_gmm_bic.png')
        plt.show()

        N_ESCOLHIDO = 4 # Escolha baseada no menor BIC
        gmm = GaussianMixture(n_components=N_ESCOLHIDO, random_state=42)
        clusters_gmm = gmm.fit_predict(dados_cluster)

        # (A) Avalia√ß√£o 2: Silhouette Score
        score_sil_gmm = silhouette_score(dados_cluster, clusters_gmm)
        print(f"GMM (n={N_ESCOLHIDO}) - Silhouette Score: {score_sil:.4f}")

    else:
        print("Clusteriza√ß√£o pulada por falta de dados suficientes.")


# ================================================================
# C√âLULA 3: APRENDIZADO SUPERVISIONADO - REGRESS√ÉO
# OBJETIVO: Prever o 'Valor_de_Venda' (num√©rico)
# ================================================================

if dados is not None:
    print("\n" + "="*50)
    print("--- Iniciando An√°lise Supervisionada (Regress√£o) ---")

    # 1. Prepara√ß√£o dos Dados
    X = dados[['Produto']]
    y = dados['Valor_de_Venda']

    # Pr√©-processador para X (One-Hot Encoding)
    preprocessor = ColumnTransformer(
        transformers=[('cat', OneHotEncoder(), ['Produto'])],
        remainder='passthrough'
    )

    # 2. Dividir em Treino e Teste
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

    # 3. Dicion√°rio de modelos
    modelos_reg = {
        "√Årvore de Decis√£o": DecisionTreeRegressor(random_state=42),
        "Random Forests": RandomForestRegressor(random_state=42, n_estimators=50),
        "KNN": KNeighborsRegressor(n_neighbors=5),
        "Rede Neural (MLP)": MLPRegressor(random_state=42, max_iter=500, hidden_layer_sizes=(64, 32), activation='relu', solver='adam')
    }

    resultados_reg = {}

    print("\n[Treinando e Avaliando Modelos de Regress√£o...]\n")

    # 4. Loop de Treinamento e Avalia√ß√£o
    for nome, modelo in modelos_reg.items():

        pipeline = Pipeline(steps=[('preprocessor', preprocessor),
                                  ('model', modelo)])

        pipeline.fit(X_train, y_train)
        y_pred = pipeline.predict(X_test)

        # (A) Avalia√ß√£o
        r2 = r2_score(y_test, y_pred)
        rmse = np.sqrt(mean_squared_error(y_test, y_pred))

        resultados_reg[nome] = {'R2': r2, 'RMSE': rmse}
        print(f"--- {nome} ---")
        print(f"  R¬≤ (R-squared): {r2:.4f}")
        print(f"  RMSE (Erro M√©dio): R$ {rmse:.4f}")

        # (B) Gr√°fico: Previsto vs. Real (Amostra)
        indices_amostra = np.random.choice(len(y_test), min(200, len(y_test)), replace=False)
        plt.figure(figsize=(8, 5))
        sns.scatterplot(x=y_test.iloc[indices_amostra], y=y_pred[indices_amostra], alpha=0.6)
        plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--')
        plt.title(f'Gr√°fico de Regress√£o: {nome}')
        plt.xlabel('Valor Real')
        plt.ylabel('Valor Previsto')
        plt.savefig(f'regressao_{nome.lower().replace(" ", "_")}.png')
        plt.show()

    # (C) Compara√ß√£o Regress√£o
    df_resultados_reg = pd.DataFrame(resultados_reg).T
    df_reg_sorted = df_resultados_reg.sort_values(by='R2', ascending=False)
    print("\n--- (C) Comparativo dos Modelos de REGRESS√ÉO ---")
    display(df_reg_sorted)


# ================================================================
# C√âLULA 4: APRENDIZADO SUPERVISIONADO - CLASSIFICA√á√ÉO
# OBJETIVO: Prever o 'Produto' (Categ√≥rico)
# ================================================================

if dados is not None:
    print("\n" + "="*50)
    print("--- Iniciando An√°lise Supervisionada (Classifica√ß√£o) ---")

    # 1. Prepara√ß√£o dos Dados
    X = dados[['Valor_de_Venda']]
    y = dados['Produto']

    # Codificador para o target
    le = LabelEncoder()
    y_encoded = le.fit_transform(y)

    # 2. Dividir em Treino e Teste
    X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.3, random_state=42)

    # 3. Pr√©-processamento (StandardScaler para X)
    scaler = StandardScaler()
    X_train_scaled = scaler.fit_transform(X_train)
    X_test_scaled = scaler.transform(X_test)

    # 4. Dicion√°rio de modelos
    modelos_clf = {
        "√Årvore de Decis√£o": DecisionTreeClassifier(random_state=42, max_depth=5),
        "Random Forests": RandomForestClassifier(random_state=42, n_estimators=50),
        "KNN": KNeighborsClassifier(n_neighbors=5),
        "Rede Neural (MLP)": MLPClassifier(random_state=42, max_iter=500, hidden_layer_sizes=(64, 32))
    }

    resultados_clf = {}

    print("\n[Treinando e Avaliando Modelos de Classifica√ß√£o...]\n")

    # 5. Loop de Treinamento e Avalia√ß√£o
    for nome, modelo in modelos_clf.items():

        modelo.fit(X_train_scaled, y_train)
        y_pred = modelo.predict(X_test_scaled)

        # (A) Avalia√ß√£o
        accuracy = accuracy_score(y_test, y_pred)
        precision = precision_score(y_test, y_pred, average='macro') # Use precision_score
        recall = recall_score(y_test, y_pred, average='macro')       # Use recall_score
        f1 = f1_score(y_test, y_pred, average='macro')               # Use f1_score


        resultados_clf[nome] = {'Acur√°cia': accuracy, 'Precis√£o': precision, 'Recall': recall, 'F1-Score': f1}
        print(f"--- {nome} ---")
        print(f"  Acur√°cia: {accuracy:.4f}")
        print(f"  F1-Score (Macro): {f1:.4f}")

        # (A.2) Matriz de Confus√£o
        cm = confusion_matrix(y_test, y_pred)

        # (B) Gr√°fico: Matriz de Confus√£o
        plt.figure(figsize=(8, 6))
        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
                    xticklabels=le.classes_, yticklabels=le.classes_)
        plt.title(f'Matriz de Confus√£o: {nome}')
        plt.xlabel('Previsto')
        plt.ylabel('Real')
        plt.savefig(f'classificacao_matriz_{nome.lower().replace(" ", "_")}.png')
        plt.show()

        # (B.2) Gr√°fico: √Årvore de Decis√£o
        if nome == "√Årvore de Decis√£o":
            plt.figure(figsize=(20, 15))
            plot_tree(modelo,
                      feature_names=['Valor_de_Venda (Normalizado)'],
                      class_names=le.classes_,
                      filled=True,
                      rounded=True,
                      fontsize=10)
            plt.title("Gr√°fico da √Årvore de Decis√£o")
            plt.savefig('classificacao_arvore_decisao.png')
            plt.show()

    # (C) Compara√ß√£o Classifica√ß√£o
    df_resultados_clf = pd.DataFrame(resultados_clf).T
    df_clf_sorted = df_resultados_clf.sort_values(by='Acur√°cia', ascending=False)
    print("\n--- (C) Comparativo dos Modelos de CLASSIFICA√á√ÉO ---")
    display(df_clf_sorted)


# ================================================================
# C√âLULA 5: COMPARATIVO FINAL (ITEM C)
# ================================================================

if dados is not None and 'df_reg_sorted' in locals() and 'df_clf_sorted' in locals():
    print("\n" + "="*50)
    print("         RESULTADO FINAL DA COMPARA√á√ÉO DE MODELOS")
    print("="*50)

    # (C) Comparar os resultados dos m√©todos (REGRESS√ÉO)
    print("\n--- Comparativo dos Modelos de REGRESS√ÉO (Prever o Pre√ßo) ---")
    display(df_reg_sorted)
    print("\n> An√°lise de Regress√£o:")
    print(f"O melhor m√©todo para prever o pre√ßo foi: **{df_reg_sorted.index[0]}**.")
    print(f"Este modelo explica {df_reg_sorted.iloc[0, 0]:.2%} da varia√ß√£o dos pre√ßos (R¬≤)")
    print(f"e tem um erro m√©dio (RMSE) de R$ {df_reg_sorted.iloc[0, 1]:.4f} por litro.")


    # (C) Comparar os resultados dos m√©todos (CLASSIFICA√á√ÉO)
    print("\n" + "="*50)
    print("\n--- Comparativo dos Modelos de CLASSIFICA√á√ÉO (Prever o Produto) ---")
    display(df_clf_sorted)
    print("\n> An√°lise de Classifica√ß√£o:")
    print(f"O melhor m√©todo para prever o tipo de produto foi: **{df_clf_sorted.index[0]}**.")
    print(f"Este modelo acertou {df_clf_sorted.iloc[0, 0]:.2%} dos produtos (Acur√°cia)")
    print(f"e obteve um F1-Score (balan√ßo entre precis√£o e recall) de {df_clf_sorted.iloc[0, 3]:.4f}.")
    print("\n" + "="*50)
    print("An√°lise conclu√≠da.")

elif dados is None:
    print("A an√°lise n√£o p√¥de ser executada pois o arquivo de dados n√£o foi carregado.")

else:
    print("A an√°lise foi executada parcialmente. Verifique os logs de erro.")